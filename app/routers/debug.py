from fastapi import APIRouter
from loguru import logger
import httpx
import json

router = APIRouter(prefix="/debug", tags=["Debug"])


@router.get("/test-openai-direct")
async def test_openai_direct():
    """Testa OpenAI diretamente e registra tudo em detalhes"""
    
    logger.info("=" * 100)
    logger.info("ğŸ§ª TESTE OPENAI DIRETO - INICIANDO")
    logger.info("=" * 100)
    
    try:
        # ===== PASSO 1: Configurar chave =====
        logger.info("\nğŸ“‹ PASSO 1: Configurando chave OpenAI")
        api_key = "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"
        logger.info(f"âœ… Chave carregada: {api_key[:30]}...{api_key[-10:]}")
        logger.info(f"âœ… Comprimento da chave: {len(api_key)} caracteres")
        
        # ===== PASSO 2: Configurar URL =====
        logger.info("\nğŸ“‹ PASSO 2: Configurando URL da API")
        url = "https://api.openai.com/v1/chat/completions"
        logger.info(f"âœ… URL: {url}")
        
        # ===== PASSO 3: Preparar headers =====
        logger.info("\nğŸ“‹ PASSO 3: Preparando headers")
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        logger.info(f"âœ… Authorization header: Bearer {api_key[:20]}...")
        logger.info(f"âœ… Content-Type: application/json")
        
        # ===== PASSO 4: Preparar payload =====
        logger.info("\nğŸ“‹ PASSO 4: Preparando payload")
        payload = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {
                    "role": "system",
                    "content": "VocÃª Ã© Luna, assistente de uma clÃ­nica odontolÃ³gica. Responda em portuguÃªs brasileiro, de forma breve (mÃ¡ximo 3 linhas), amigÃ¡vel e profissional."
                },
                {
                    "role": "user",
                    "content": "OlÃ¡! Como vocÃª pode me ajudar?"
                }
            ],
            "temperature": 0.7,
            "max_tokens": 150
        }
        logger.info(f"âœ… Model: {payload['model']}")
        logger.info(f"âœ… Mensagens: {len(payload['messages'])} mensagens")
        logger.info(f"âœ… Payload JSON preparado com sucesso")
        
        # ===== PASSO 5: Enviar requisiÃ§Ã£o =====
        logger.info("\nğŸ“‹ PASSO 5: Enviando requisiÃ§Ã£o para OpenAI")
        logger.info(f"ğŸš€ Iniciando conexÃ£o com {url}")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            logger.info("âœ… Cliente HTTP async criado")
            logger.info("ğŸŒ Enviando POST request...")
            
            response = await client.post(
                url,
                json=payload,
                headers=headers,
                timeout=30.0
            )
            
            # ===== PASSO 6: Analisar resposta =====
            logger.info("\nğŸ“‹ PASSO 6: Analisando resposta")
            logger.info(f"âœ… Resposta recebida!")
            logger.info(f"âœ… Status HTTP: {response.status_code}")
            
            response_text = response.text
            logger.info(f"\nğŸ“„ Corpo da resposta (primeiros 500 chars):")
            logger.info(f"{response_text[:500]}")
            
            # ===== PASSO 7: Processar resultado =====
            logger.info("\nğŸ“‹ PASSO 7: Processando resultado")
            
            if response.status_code == 200:
                logger.info("âœ… Status 200 OK!")
                result = response.json()
                logger.info(f"âœ… JSON parseado com sucesso")
                
                ai_message = result['choices'][0]['message']['content']
                logger.info(f"âœ… Resposta IA: {ai_message}")
                
                logger.info("\n" + "=" * 100)
                logger.info("âœ…âœ…âœ… TESTE CONCLUÃDO COM SUCESSO! âœ…âœ…âœ…")
                logger.info("=" * 100)
                
                return {
                    "status": "âœ… SUCESSO TOTAL",
                    "http_status": 200,
                    "ai_response": ai_message,
                    "message": "A API OpenAI estÃ¡ funcionando perfeitamente!"
                }
            
            elif response.status_code == 401:
                logger.error(f"\nâŒ ERRO 401: Unauthorized")
                logger.error(f"âŒ A chave API pode estar invÃ¡lida ou expirada")
                
                return {
                    "status": "âŒ ERRO 401 - UNAUTHORIZED",
                    "http_status": 401,
                    "error": response_text,
                    "message": "Chave API invÃ¡lida ou expirada"
                }
            
            else:
                logger.error(f"\nâŒ ERRO HTTP {response.status_code}")
                logger.error(f"âŒ Resposta: {response_text}")
                
                return {
                    "status": f"âŒ ERRO HTTP {response.status_code}",
                    "http_status": response.status_code,
                    "error": response_text,
                    "message": f"Problema ao conectar com OpenAI (HTTP {response.status_code})"
                }
    
    except httpx.TimeoutException as e:
        logger.error(f"\nâŒ TIMEOUT")
        logger.error(f"âŒ Erro: {str(e)}")
        
        return {
            "status": "âŒ TIMEOUT",
            "error": "RequisiÃ§Ã£o demorou mais de 30 segundos",
            "message": "A API OpenAI estÃ¡ muito lenta"
        }
    
    except Exception as e:
        logger.error(f"\nâŒ EXCEÃ‡ÃƒO GERAL")
        logger.error(f"âŒ Tipo: {type(e).__name__}")
        logger.error(f"âŒ Mensagem: {str(e)}")
        import traceback
        logger.error(f"\nâŒ Traceback:\n{traceback.format_exc()}")
        
        return {
            "status": "âŒ ERRO GERAL",
            "error": str(e),
            "type": type(e).__name__,
            "message": "Verifique o arquivo debug.log para mais detalhes"
        }


@router.get("/logs")
async def get_logs():
    """Retorna os Ãºltimos logs"""
    logger.info("ğŸ“‹ Endpoint /debug/logs acessado")
    
    try:
        with open("debug.log", "r", encoding="utf-8") as f:
            logs_content = f.read()
        
        lines = logs_content.split("\n")
        recent_logs = "\n".join(lines[-50:])
        
        logger.info(f"âœ… Retornando {len(lines)} linhas de log")
        
        return {
            "status": "âœ… Logs carregados",
            "total_lines": len(lines),
            "recent_logs": recent_logs
        }
    
    except FileNotFoundError:
        logger.error("âŒ Arquivo debug.log nÃ£o encontrado")
        return {
            "status": "âŒ Arquivo nÃ£o encontrado",
            "error": "Execute /debug/test-openai-direct primeiro"
        }
    
    except Exception as e:
        logger.error(f"âŒ Erro ao ler logs: {str(e)}")
        return {
            "status": "âŒ Erro",
            "error": str(e)
        }


@router.get("/status")
async def debug_status():
    """Retorna status do debug"""
    logger.info("ğŸ“Š /debug/status acessado")
    
    return {
        "status": "ğŸŸ¢ Debug ativo",
        "endpoints": {
            "test": "/debug/test-openai-direct",
            "logs": "/debug/logs",
            "status": "/debug/status"
        }
    }
